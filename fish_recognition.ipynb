{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4562bdd7-144b-473c-ac56-ea0a816685ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define source dataset folder (where the current dataset is stored)\n",
    "source_folder = r\"C:/Users/abina/Downloads/archive\"  # Modify this to your dataset location\n",
    "\n",
    "# Define destination folder correctly\n",
    "destination_folder = r\"C:/Users/abina/fish_recognition/dataset\"\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1969f4d-3c79-44bb-b89c-00b43c215c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders found: ['test', 'train', 'val']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "source_folder = r\"C:/Users/abina/Downloads/archive/FishImgDataset\"\n",
    "print(\"Folders found:\", os.listdir(source_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265becbb-dc06-4dec-bb97-57ec53bb48d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Source Folder Contents: ['FishImgDataset']\n",
      "üîÑ Moving C:/Users/abina/Downloads/archive\\FishImgDataset ‚Üí C:/Users/abina/fish_recognition/dataset\\FishImgDataset\n",
      "üìÇ Folders in Project Dataset: ['FishImgDataset']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "source_folder = r\"C:/Users/abina/Downloads/archive\"\n",
    "destination_folder = r\"C:/Users/abina/fish_recognition/dataset\"\n",
    "\n",
    "# Ensure destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Get all folders inside the source dataset\n",
    "folders = os.listdir(source_folder)\n",
    "\n",
    "print(f\"üìÇ Source Folder Contents: {folders}\")  # Debugging step\n",
    "\n",
    "# Move each folder into the project's dataset\n",
    "for folder in folders:\n",
    "    source_path = os.path.join(source_folder, folder)\n",
    "    destination_path = os.path.join(destination_folder, folder)\n",
    "\n",
    "    # Ensure it's a valid folder before moving\n",
    "    if os.path.isdir(source_path):\n",
    "        print(f\"üîÑ Moving {source_path} ‚Üí {destination_path}\")  # Debugging step\n",
    "        shutil.move(source_path, destination_path)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Skipped (Not a folder): {source_path}\")  # Debugging step\n",
    "\n",
    "# Final verification\n",
    "print(\"üìÇ Folders in Project Dataset:\", os.listdir(destination_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1535687-a284-4cd7-b05d-0d6fc4c61cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abina\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abina\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training directory: C:/Users/abina/fish_recognition/dataset/FishImgDataset\\train\n",
      "‚úÖ Validation directory: C:/Users/abina/fish_recognition/dataset/FishImgDataset\\val\n",
      "üìÇ Total Classes: 31\n",
      "üìÇ Class Names: ['Bangus', 'Big Head Carp', 'Black Spotted Barb', 'Catfish', 'Climbing Perch', 'Fourfinger Threadfin', 'Freshwater Eel', 'Glass Perchlet', 'Goby', 'Gold Fish', 'Gourami', 'Grass Carp', 'Green Spotted Puffer', 'Indian Carp', 'Indo-Pacific Tarpon', 'Jaguar Gapote', 'Janitor Fish', 'Knifefish', 'Long-Snouted Pipefish', 'Mosquito Fish', 'Mudfish', 'Mullet', 'Pangasius', 'Perch', 'Scat Fish', 'Silver Barb', 'Silver Carp', 'Silver Perch', 'Snakehead', 'Tenpounder', 'Tilapia']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load ResNet-18 for feature extraction\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.fc = torch.nn.Identity()  # Remove the classification layer to get feature embeddings\n",
    "resnet18.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Define dataset paths using absolute paths\n",
    "dataset_path = r\"C:/Users/abina/fish_recognition/dataset/FishImgDataset\"\n",
    "train_dir = os.path.join(dataset_path, \"train\")\n",
    "val_dir = os.path.join(dataset_path, \"val\")\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  \n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "val_data = datasets.ImageFolder(val_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Debugging print statements to verify dataset loading\n",
    "print(f\"‚úÖ Training directory: {train_dir}\")\n",
    "print(f\"‚úÖ Validation directory: {val_dir}\")\n",
    "print(f\"üìÇ Total Classes: {len(train_data.classes)}\")\n",
    "print(\"üìÇ Class Names:\", train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccaf7c84-28ef-4b8a-8e59-1dd0e476b4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete!\n"
     ]
    }
   ],
   "source": [
    "def extract_features(model, loader):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            outputs = model(images)  \n",
    "            features.append(outputs.view(outputs.shape[0], -1).numpy())  \n",
    "            labels.extend(targets.numpy())  \n",
    "\n",
    "    return np.vstack(features).astype(np.float32), np.array(labels).astype(np.int64)\n",
    "\n",
    "\n",
    "# Extract features for training & validation\n",
    "X_train, y_train = extract_features(resnet18, train_loader)\n",
    "X_test, y_test = extract_features(resnet18, val_loader)\n",
    "\n",
    "print(\"Feature extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3392c8d2-12fc-4b49-b6cc-622b586dbe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model Training Complete!\n",
      "üìà SVM Accuracy on Validation Set: 98.69%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train SVM model\n",
    "svm = SVC(kernel=\"linear\")  # You can change \"linear\" to \"rbf\" for a nonlinear classifier\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on validation data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ Model Training Complete!\")\n",
    "print(f\"üìà SVM Accuracy on Validation Set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "175cb613-a7ca-4b55-9a2f-0389848e64f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SVM model saved at: C:/Users/abina/fish_recognition/models\\svm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define the model save path\n",
    "model_folder = r\"C:/Users/abina/fish_recognition/models\"\n",
    "os.makedirs(model_folder, exist_ok=True)  # Ensure the folder exists\n",
    "\n",
    "model_path = os.path.join(model_folder, \"svm_model.pkl\")\n",
    "\n",
    "# Save the trained SVM model\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(svm, f)\n",
    "\n",
    "print(f\"‚úÖ SVM model saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13e152ff-dc43-43a1-8dc8-c749750b92c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Exists: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Exists:\", os.path.exists(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63f02aa4-a262-4f9c-b4a1-34d7ec83c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_labels={0:\"Bangus\", 1:\"Big Head Carp\", 2:\"Black Spotted Barb\", 3:\"Catfish\", 4:\"Climbing Perch\", 5: \"Fourfinger Threadfin\", 6:\"Freshwater Eel\", 7:\"Glass Perchlet\",8:\"Goby\", 9:\"Gold Fish\", 10:\"Gourami\", 11:\"Grass Carp\", 12:\"Green Spotted Puffer\", 13:\"Indian Carp\", 14:\"Indo-Pacific Tarpon\", 15:\"Jaguar Gapote\", 16:\"Janitor Fish\", 17:\"Knifefish\", 18:\"Long-Snouted Pipefish\", 19:\"Mosquito Fish\", 20:\"Mudfish\", 21:\"Mullet\", 22:\"Pangasius\", 23:\"Perch\", 24:\"Scat Fish\", 25:\"Silver Barb\", 26:\"Silver Carp\", 27:\"Silver Perch\", 28:\"Snakehead\", 29:\"Tenpounder\", 30:\"Tilapia\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4502b1b6-dfeb-484a-a72c-0addea114626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\abina/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\abina\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abina\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Predicted fish category: Gourami \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the saved SVM model\n",
    "with open(model_path, \"rb\") as f:\n",
    "    svm_model = pickle.load(f)\n",
    "\n",
    "# Load ResNet for feature extraction\n",
    "resnet18 = torch.hub.load(\"pytorch/vision:v0.10.0\", \"resnet18\", pretrained=True)\n",
    "resnet18.fc = torch.nn.Identity()\n",
    "resnet18.eval()\n",
    "\n",
    "# Image transformation pipeline (matches Flask processing)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_features(image):\n",
    "    \"\"\"Extract features from an image using ResNet18.\"\"\"\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = resnet18(image).flatten().numpy()\n",
    "    return features\n",
    "\n",
    "# Test with n image\n",
    "image_path = \"C:/Users/abina/Downloads/Gourami 79.jpg\" # Replace with actual image path\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Extract features and classify\n",
    "features = extract_features(image)\n",
    "prediction = svm_model.predict([features])[0]\n",
    "fish_label = fish_labels.get(prediction, \"Unknown Fish\")\n",
    "\n",
    "print(f\"‚úÖ Predicted fish category: {fish_label} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e0928-5bb8-4074-a78d-bbc5fc163328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
